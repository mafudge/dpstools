{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a5ce70-6456-4ae5-8d7d-4d64f0c7ae39",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chat DPS\n",
    "\n",
    "This program uses GPT 3.5 + Langchain to allow you to summarize and ask questions of PDF files.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Run the first cell to install the requirements. These might take a minute\n",
    "- Restart the Notebook Kernel (Circle Arrow Icon in Toolbar)\n",
    "- Run the code. It will find PDF files in the same folder as the script\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4de1d3-91a7-4a9c-a109-9da0fd5ff941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell, then restart the notebook\n",
    "!pip install --user -q langchain pypdf chromadb tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7717b3e8-09dd-4182-852a-a2ed651ddcb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>ChatDPS</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Use Chat GPT to ask questions of an assigned reading. For best results, keep your questions short and concise! ALWAYS VERIFY THE OUTPUT!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Select a reading to load:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21865c207184584959e61470e3f9d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='reading', options=('IMLS_CompLit_2017.pdf',), value='IMLS_CompLit_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import glob\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact_manual, widgets\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "readings = glob.glob(\"*.pdf\")\n",
    "\n",
    "display(HTML(\"<h1>ChatDPS</h1>\"))\n",
    "display(HTML(\"Use Chat GPT to ask questions of an assigned reading. For best results, keep your questions short and concise! ALWAYS VERIFY THE OUTPUT!\"))\n",
    "display(HTML(\"Select a reading to load:\"))\n",
    "\n",
    "def log(file, results):\n",
    "    with open(file, \"a\") as f:\n",
    "        f.write(results)\n",
    "\n",
    "def history(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "choose_reading_interact=widgets.interact_manual.options(manual_name=\"Q&A This reading.\")\n",
    "@choose_reading_interact(reading=readings)\n",
    "def choose_reading(reading):\n",
    "    loader = PyPDFLoader(reading)\n",
    "    pages = loader.load_and_split()\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=250) \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    db = Chroma.from_documents(pages,embeddings)\n",
    "    retriever = db.as_retriever()\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever) \n",
    "    qa_interact=widgets.interact_manual.options(manual_name=\"Ask!\")\n",
    "\n",
    "    chatlog = reading.lower().replace(\".pdf\",\".log\")\n",
    "\n",
    "    qabox = widgets.Textarea()\n",
    "    display(HTML(\"Ask Your Questions:\"))\n",
    "\n",
    "    @qa_interact(question=qabox)\n",
    "    def q_and_a(question):\n",
    "        answer = qa.run(question)\n",
    "        results = f\"<p><b>Question:</b><br>{question}\\n\"\n",
    "        results += f\"<p><b>Answer:</b><br><code>{answer}</code>\\n<hr>\\n\"\n",
    "        log(chatlog, results)\n",
    "        display(HTML(history(chatlog)))\n",
    "        qabox.value = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a6fcd-b33f-4dbd-9e78-2280b24c2b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
